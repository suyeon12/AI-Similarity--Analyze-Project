{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63909c1f",
   "metadata": {},
   "source": [
    "# kcBERT QA를 이용하여 형량 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035a0dc",
   "metadata": {},
   "source": [
    "## 1. 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc504d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, QuestionAnsweringPipeline\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook\n",
    "import math\n",
    "import urllib.request\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3c0d4",
   "metadata": {},
   "source": [
    "## 2. Base Model & Tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5caec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d871a13b3b4da389badf8218d02c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6127aa15cefa4739a3ea6fb2bf3a9dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086fa9d87c504966870ad99a3b792ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d0417545e947a8aa5f17d2a635fc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/244k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained('beomi/kcbert-base', from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('beomi/kcbert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4321868",
   "metadata": {},
   "source": [
    "## 3. Pipeline 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96494f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = QuestionAnsweringPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5bc24",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning\n",
    "- korquad(한국어 QA 데이터 셋)을 이용한 파인튜닝([링크](https://korquad.github.io/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30e4d7",
   "metadata": {},
   "source": [
    "### 1) korquad 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8641ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://korquad.github.io/dataset/KorQuAD_v1.0_train.json', 'korquad.json')\n",
    "korquad = json.load(open('korquad.json', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d63377",
   "metadata": {},
   "source": [
    "### 2) Input 데이터 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a573436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def make_inputs(context, qas):\n",
    "    inputs = tokenizer(\n",
    "        context, \n",
    "        qas['question'], \n",
    "        truncation=True, \n",
    "        max_length=tokenizer.model_max_length)\n",
    "    q = qas['answers'][0]\n",
    "    start_char = q['answer_start']\n",
    "    end_char = start_char + len(q['text']) - 1\n",
    "    start = inputs.char_to_token(0, start_char)\n",
    "    end = inputs.char_to_token(0, end_char)\n",
    "    inputs['start_positions'] = [start]\n",
    "    inputs['end_positions'] = [end]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296aacd2",
   "metadata": {},
   "source": [
    "### 3) Input 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c6f0d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 0\n",
    "filename = 'korquad.tfrecord'\n",
    "with tf.io.TFRecordWriter(filename) as writer:\n",
    "    for item in korquad['data']:   # 각 아이템 순환\n",
    "        for para in item['paragraphs']:  # 아이템마다 \n",
    "            context = para['context']\n",
    "            for qas in para['qas']:\n",
    "                inputs = make_inputs(context, qas)\n",
    "                if inputs['start_positions'][0] and inputs['end_positions'][0]:\n",
    "                    feature = {k: int_feature(v) for k, v in inputs.items()}\n",
    "                    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                    s = example.SerializeToString()\n",
    "                    writer.write(s)\n",
    "                    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed875b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_seq = tf.io.FixedLenSequenceFeature(shape=(), dtype=tf.int64, allow_missing=True)\n",
    "int_value = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "feature_description = {\n",
    "    'input_ids': int_seq,\n",
    "    'token_type_ids': int_seq,\n",
    "    'attention_mask': int_seq,\n",
    "    'start_positions': int_value,\n",
    "    'end_positions': int_value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2cd47ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(example):\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example = {k : tf.cast(v, tf.int32) for k, v in example.items()}\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dafe596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# korquad 데이터셋 불러오기\n",
    "dataset = tf.data.TFRecordDataset(['korquad.tfrecord']).map(preproc).padded_batch(8)\n",
    "batch = next(iter(dataset))\n",
    "result = model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0596afe4",
   "metadata": {},
   "source": [
    "### 4) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a0d4045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afb59c9231245acb48da889b2572f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 옵티마이저는 adam\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "\n",
    "n = 57653\n",
    "for batch in tqdm.notebook.tqdm(dataset, total=math.ceil(n / 32)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        result = model(batch)\n",
    "        loss = tf.reduce_mean(result['loss'])\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables)) # loss가 감소하는 방향으로 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce116587",
   "metadata": {},
   "source": [
    "## 5. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3515d",
   "metadata": {},
   "source": [
    "### 1) QA function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2a3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(question, context):\n",
    "    inputs = tokenizer(context, question, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    outputs = model(inputs)\n",
    "    start = tf.argmax(outputs.start_logits, axis=1).numpy()[0]\n",
    "    end = tf.argmax(outputs.end_logits, axis=1).numpy()[0]\n",
    "    return tokenizer.decode(inputs['input_ids'][0, start:end+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aa59a4",
   "metadata": {},
   "source": [
    "### 2) Simple data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d163778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"피고에게 징역 62년의 형량을 선고한다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91d7df7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'징역 62년'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"형량은 얼마인가?\", context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025dbc6",
   "metadata": {},
   "source": [
    "### 3) complex data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "689b6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"원심판결을 파기한다.\n",
    "\n",
    "피고인을 금고 4월에 처한다.\n",
    "1. 항소이유의 요지\n",
    "\n",
    "원심이 선고한 형(금고 1년에 집행유예 2년)에 대하여 피고인은 너무 무거워서, 검사는 너무 가벼워서 부당하다고 각각 주장한다.\n",
    "\n",
    "2. 판 단\n",
    "\n",
    "피고인이 이 사건 범행을 인정하면서 잘못을 반성하고 있고, 피해자 ●●●의 유족 및 피해자 ◎◎◎과 각 합의하여 이들이 피고인의 처벌을 원치 않는 점, 피고인에게 소년보호처분 이외에 전과가 없는 점은 인정된다.\n",
    "\n",
    "그러나 이 사건 범행은 피고인이 제한속도가 시속 80km인 도로를 시속 200km가 넘는 속도로 과속운전을 하다가 발생한 것으로 피고인의 주의의무 위반의 정도가 매우 크고, 이 사건으로 인하여 피해 차량의 운전자가 사망하고, 가해 차량의 동승자가 중상을 입는 중대한 결과가 초래된 점에서, 피고인에게는 그에 상응하는 처벌이 필요하다.\n",
    "\n",
    "위와 같은 사정들과 그 밖에 피고인의 성행, 환경, 범행 후의 정황 등 기록과 변론에 나타난 모든 양형조건을 종합하여 보면, 원심이 선고한 형은 너무 가벼워서 부당하다.\n",
    "\n",
    "3. 결 론\n",
    "\n",
    "그렇다면 검사의 항소는 이유 있으므로 형사소송법 제364조 제6항에 따라 원심판결을 파기하고, 변론을 거쳐 다시 다음과 같이 판결한다(피고인의 항소는 이유 없으나, 검사의 항소를 받아들여 원심판결을 파기하는 이상 따로 주문에서 피고인의 항소를 기각하지 아니한다).\n",
    "\n",
    "범죄사실 및 증거의 요지\n",
    "\n",
    "이 법원이 인정하는 범죄사실 및 증거의 요지는 원심판결 각 해당란 기재와 같으므로 형사소송법 제369조에 따라 그대로 인용한다.\n",
    "\n",
    "법령의 적용\n",
    "\n",
    "1. 범죄사실에 대한 해당법조\n",
    "\n",
    "교통사고처리 특례법 제3조 제1항, 형법 제268조(업무상과실치사의 점), 교통사고처리 특례법 제3조 제1항, 제2항 단서 제3호, 형법 제268조(업무상과실치상의 점)\n",
    "\n",
    "1. 상상적 경합\n",
    "\n",
    "형법 제40조, 제50조[죄질이 더 무거운 교통사고처리특례법위반(치사)죄에 정한 형으로 처벌]\n",
    "\n",
    "1. 형의 선택\n",
    "\n",
    "금고형 선택\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cf47937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2년'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"최종판결의 형량은 무엇인가?\", context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa3136",
   "metadata": {},
   "source": [
    "- 기계독해를 이용하여 형량을 집계한 후 중앙값, 평균, 최빈값의 형식으로 예상형량을 보여준다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
